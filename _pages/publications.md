---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

 You can also find my articles on my [Google Scholar](https://scholar.google.com.tw/citations?hl=zh-TW&view_op=list_works&gmla=AJsN-F6xkDgwUinMUPcclzH8MvpfS73YI5T8bGf-6u8Cdd4dNoEosD0G1N2B4EULSA-maNBpiywVrDFa7uO5EFfzgYjgj6Uv6nydNcCHdKDvWZtjk_MN01Q&user=cJ5oowQAAAAJ) profile.

## 2023
### Planning as In-Painting: A Diffusion-Based Embodied Task Planning Framework for Environments under Uncertainty
<span style='font-size:0.9em'>**Cheng-Fu Yang**, Haoyang Xu, Te-Lin Wu, Xiaofeng Gao, Kai-Wei Chang, Feng Gao</span>
<span style='font-size:0.9em'>*Arxiv 2023*</span>
<div>
  |<a href="https://arxiv.org/abs/2310.12344" target="_blank">paper</a> |
  <a href="https://github.com/joeyy5588/planning-as-inpainting" target="_blank">code</a> |
</div>

### LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following
<span style='font-size:0.9em'>**Cheng-Fu Yang**, Yen-Chun Chen, Jianwei Yang, Xiyang Dai, Lu Yuan, Yu-Chiang Frank Wang, Kai-Wei Chang</span>
<span style='font-size:0.9em'>*Accepted to EMNLP 2023*</span>
<div>
  |<a href="https://arxiv.org/abs/2310.12344" target="_blank">paper</a> |
  <a href="https://github.com/joeyy5588/LACMA" target="_blank">code</a> |
</div>

## 2022

### Paraphrasing is all you need for Novel Object Captioning
<span style='font-size:0.9em'>**Cheng-Fu Yang**, Yao-Hung Hubert Tsai, Wan-Cyuan Fan, Yu-Chiang Frank Wang, Louis-Philippe Morency, Ruslan Salakhutdinov</span>
<span style='font-size:0.9em'>*Accepted to NeurIPS 2022*</span>
<div>
  |<a href="https://arxiv.org/abs/2209.12343" target="_blank">paper</a> |
  <a href="https://github.com/joeyy5588/P2C" target="_blank">code</a> |
</div>

### Target-free Text-guided Image Manipulation
<span style='font-size:0.9em'>Wan-Cyuan Fan, **Cheng-Fu Yang**, Qiao-An Yang, Yu-Chiang Frank Wang</span>
<span style='font-size:0.9em'>*Accepted to AAAI 2023*</span>
<div>
  |<a href="https://arxiv.org/abs/2211.14544" target="_blank">paper</a> |
</div>

### Scene Graph Expansion for Semantics-Guided Image Completion
<span style='font-size:0.9em'>Qiao-An Yang, **Cheng-Fu Yang**, Wan-Cyuan Fan, Cheng-Yo Tan, Meng-Lin Wu, Yu-Chiang Frank Wang</span>
<span style='font-size:0.9em'>*Accepted to CVPR 2022*</span>
<div>
  |<a href="ttps://arxiv.org/abs/2205.02958" target="_blank">paper</a> |
</div>

### Cross-Modal Mutual Learning for Audio-Visual Speech Recognition and Manipulation
<span style='font-size:0.9em'>Chih-Chun Yang, **Cheng-Fu Yang**, Wan-Cyuan Fan and Yu-Chiang Frank Wang</span>
<span style='font-size:0.9em'>*Accepted to AAAI 2022*</span>
<div>
  |<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20210" target="_blank">paper</a> |
</div>


## 2021

### LayoutTransformer: Scene Layout Generation with Conceptual and Spatial Diversity
<span style='font-size:0.9em'>**Cheng-Fu Yang\***, Wan-Cyuan Fan\*, Fu-En Yang and Yu-Chiang Frank Wang.</span>
<span style='font-size:0.9em'>*Accepted to CVPR 2021*</span>
<div>
  |<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_LayoutTransformer_Scene_Layout_Generation_With_Conceptual_and_Spatial_Diversity_CVPR_2021_paper.html" target="_blank">paper</a> |
  <a href="https://github.com/davidhalladay/LayoutTransformer" target="_blank">code</a> |
</div>

